---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/

title: Uncorrelated multilinear principal component analysis through successive variance
  maximization
subtitle: ''
summary: ''
authors:
- Haiping Lu
- Konstantinos N Plataniotis
- Anastasios N Venetsanopoulos
tags: []
categories: []
date: '2008-07-01'
lastmod: 2021-12-29T13:49:35Z
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2021-12-29T13:49:34.221394Z'
publication_types:
- '1'
abstract: 'Tensorial data are frequently encountered in various machine learning tasks today and dimensionality reduction is one of their most important applications. This paper extends the classical principal component analysis (PCA) to its multilinear version by proposing a novel unsupervised dimensionality reduction algorithm for tensorial data, named as uncorrelated multilinear PCA (UMPCA). UMPCA seeks a tensor-to-vector projection that captures most of the variation in the original tensorial input while producing uncorrelated features through successive variance maximization. We evaluate the UMPCA on a second-order tensorial problem, face recognition, and the experimental results show its superiority, especially in low-dimensional spaces, through the comparison with three other PCA-based algorithms.'
publication: '*International Conference on Machine Learning (ICML)*'
links:
- name: Link
  url: https://dl.acm.org/doi/10.1145/1390156.1390234
- name: PDF
  url: http://icml2008.cs.helsinki.fi/papers/163.pdf
---
