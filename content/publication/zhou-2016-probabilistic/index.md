---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/

title: Probabilistic rank-one matrix analysis with concurrent regularization
subtitle: ''
summary: ''
authors:
- Yang Zhou
- Haiping Lu
tags: []
categories: []
date: '2016-07-01'
lastmod: 2021-12-29T13:50:02Z
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2021-12-29T13:50:01.282522Z'
publication_types:
- '1'
abstract: 'As a classical subspace learning method, Probabilistic PCA (PPCA) has been extended to several bilinear variants for dealing with matrix observations. However, they are all based on the Tucker model, leading to a restricted subspace representation and the problem of rotational ambiguity. To address these problems, this paper proposes a bilinear PPCA method named as Probabilistic Rank-One Matrix Analysis (PROMA). PROMA is based on the CP model, which leads to a more flexible subspace representation and does not suffer from rotational ambiguity. For better generalization, concurrent regularization is introduced to regularize the whole matrix subspace, rather than column and row factors separately. Experiments on both synthetic and real-world data demonstrate the superiority of PROMA in subspace estimation and classification as well as the effectiveness of concurrent regularization in regularizing bilinear PPCAs.'
publication: '*International Joint Conference on Artificial Intelligence (IJCAI)*'
links:
- name: Link
  url: https://dl.acm.org/doi/10.5555/3060832.3060961
---
